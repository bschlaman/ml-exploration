{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Practice on the MNIST data set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "from array import array\n",
    "\n",
    "\n",
    "class MnistDataloader(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        training_images_filepath,\n",
    "        training_labels_filepath,\n",
    "        test_images_filepath,\n",
    "        test_labels_filepath,\n",
    "    ):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "\n",
    "    def read_images_labels(self, images_filepath, labels_filepath):\n",
    "        labels = []\n",
    "        with open(labels_filepath, \"rb\") as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError(\n",
    "                    \"Magic number mismatch, expected 2049, got {}\".format(magic)\n",
    "                )\n",
    "            labels = array(\"B\", file.read())\n",
    "\n",
    "        with open(images_filepath, \"rb\") as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError(\n",
    "                    \"Magic number mismatch, expected 2051, got {}\".format(magic)\n",
    "                )\n",
    "            image_data = array(\"B\", file.read())\n",
    "        images = []\n",
    "        for i in range(size):\n",
    "            images.append([0] * rows * cols)\n",
    "        for i in range(size):\n",
    "            img = np.array(image_data[i * rows * cols : (i + 1) * rows * cols])\n",
    "            img = img.reshape(28, 28)\n",
    "            images[i][:] = img\n",
    "\n",
    "        return images, labels\n",
    "\n",
    "    def load_data(self):\n",
    "        x_train, y_train = self.read_images_labels(\n",
    "            self.training_images_filepath, self.training_labels_filepath\n",
    "        )\n",
    "        x_test, y_test = self.read_images_labels(\n",
    "            self.test_images_filepath, self.test_labels_filepath\n",
    "        )\n",
    "        return (x_train, y_train), (x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "data_base_path = \"../data/mnist\"\n",
    "training_images_filepath = os.path.join(\n",
    "    data_base_path, \"train-images-idx3-ubyte/train-images-idx3-ubyte\"\n",
    ")\n",
    "training_labels_filepath = os.path.join(\n",
    "    data_base_path, \"train-labels-idx1-ubyte/train-labels-idx1-ubyte\"\n",
    ")\n",
    "test_images_filepath = os.path.join(\n",
    "    data_base_path, \"t10k-images-idx3-ubyte/t10k-images-idx3-ubyte\"\n",
    ")\n",
    "test_labels_filepath = os.path.join(\n",
    "    data_base_path, \"t10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte\"\n",
    ")\n",
    "\n",
    "\n",
    "def show_images(images, title_texts):\n",
    "    cols = 5\n",
    "    rows = int(len(images) / cols) + 1\n",
    "    plt.figure(figsize=(30, 20))\n",
    "    index = 1\n",
    "    for x in zip(images, title_texts):\n",
    "        image = x[0]\n",
    "        title_text = x[1]\n",
    "        plt.subplot(rows, cols, index)\n",
    "        plt.imshow(image, cmap=plt.cm.gray)\n",
    "        if title_text != \"\":\n",
    "            plt.title(title_text, fontsize=15)\n",
    "        index += 1\n",
    "\n",
    "\n",
    "mnist_dataloader = MnistDataloader(\n",
    "    training_images_filepath,\n",
    "    training_labels_filepath,\n",
    "    test_images_filepath,\n",
    "    test_labels_filepath,\n",
    ")\n",
    "(x_train, y_train), (x_test, y_test) = mnist_dataloader.load_data()\n",
    "\n",
    "images_2_show = []\n",
    "titles_2_show = []\n",
    "for i in range(0, 10):\n",
    "    r = random.randint(1, 60000)\n",
    "    images_2_show.append(x_train[r])\n",
    "    titles_2_show.append(f\"training image [{str(r)}] = {str(y_train[r])}\")\n",
    "\n",
    "for i in range(0, 5):\n",
    "    r = random.randint(1, 10000)\n",
    "    images_2_show.append(x_test[r])\n",
    "    titles_2_show.append(f\"test image [{str(r)}] = {str(y_test[r])}\")\n",
    "\n",
    "show_images(images_2_show, titles_2_show)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifying the shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    [\n",
    "        (\"x_train\", type(x_train), \"Raw image data\"),\n",
    "        (\n",
    "            \"x_train[0]\",\n",
    "            type(x_train[0]),\n",
    "            \"2D array representing pixel values for a single image\",\n",
    "        ),\n",
    "        (\"y_train\", type(y_train), \"Labels\"),\n",
    "    ],\n",
    "    columns=[\"variable\", \"type\", \"description\"],\n",
    ")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train), len(x_train[0]), len(x_train[0][0]), type(x_train[0][0]), type(x_train[0][0][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct input and output layers\n",
    "\n",
    "The next step is to construct a random neural network.  I'll start by constructing the input layer and output layer.\n",
    "\n",
    "First, define some utilities:\n",
    "\n",
    "1. need a way to flatten a 28x28 image into a single list\n",
    "2. need a method to normalize a list of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from typing import Iterable, Sequence, TypeVar\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "# unused\n",
    "def _flatten_2d_data(data: Iterable[Iterable[T]]) -> itertools.chain[T]:\n",
    "    \"\"\"Flatten a 2d matrix into a 1d matrix by\n",
    "    chaining together each row.\n",
    "\n",
    "    Note: this function is unused; I just like the use of generics!\n",
    "    \"\"\"\n",
    "    return itertools.chain.from_iterable(data)\n",
    "\n",
    "def normalize(a: np.ndarray) -> np.ndarray:\n",
    "    return a / np.sum(a)\n",
    "\n",
    "\n",
    "def construct_random_weights_matrix(input_size: int, output_size: int) -> np.ndarray:\n",
    "    \"\"\"Returns a matrix of random values taken from the\n",
    "    standard normal distribution and scaled down by a reasonable constant\n",
    "\n",
    "    Note: the arguments are ordered input -> output; this is the opposite\n",
    "    order for how matrices are described (rows, columns)\n",
    "    \"\"\"\n",
    "    return np.random.randn(output_size, input_size) * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert training data into an np.ndarray to examine its shape\n",
    "pixel_grid = np.array(x_train[0])\n",
    "\n",
    "input_layer = pixel_grid.flatten()\n",
    "output_layer = np.zeros(len(set(y_train))) # 10 possible categories\n",
    "\n",
    "print(f\"{pixel_grid.shape=}\")\n",
    "print(f\"{input_layer.shape=}\")\n",
    "print(f\"{output_layer.shape=}\")\n",
    "print(f\"{output_layer=}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct random weights matrix\n",
    "\n",
    "`np.random.randn` returns values from the standard normal distribution, a common initialization\n",
    "method for neural networks.\n",
    "\n",
    "The matrix must be of size `len(output)` x `len(input)`, which makes sense as a linear transformation\n",
    "from dimensionality 784 to dimensionality 10.\n",
    "\n",
    "Here I scale the inital weights by 0.01, a relatively arbitrary value.  The values should be small because in a network with many layers, large initial weights can lead to large outputs from neurons, which when passed through an activation function (like a sigmoid or a tanh), might end up in the saturation region of the function. This can lead to vanishing gradients during backpropagation, making the network harder to train.\n",
    "\n",
    "Note that techniques like Xavier initialization and He initialization improve upon this random method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the weights with small random values\n",
    "weights = np.random.randn(output_layer.size, input_layer.size) * 0.01\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting one image\n",
    "\n",
    "Now find the output of applying the weights to the first image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label1 = y_train[0]\n",
    "print(f\"{input_layer.shape=} {label1=}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = np.dot(weights, input_layer)\n",
    "output1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = normalize(output1)\n",
    "output1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function\n",
    "\n",
    "Now define the *loss function*; I'll use the common **squared error loss**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(label: int, output_layer: np.ndarray) -> float:\n",
    "    \"\"\"Squared error loss.\"\"\"\n",
    "    if abs(np.sum(output_layer) - 1) > 0.000001:\n",
    "        raise Exception(\"output_layer must be normalized\")\n",
    "    return sum(\n",
    "        val**2 if i != label else (val - 1) ** 2 for i, val in enumerate(output_layer)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(label1, output1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenges for next steps\n",
    "\n",
    "- Can I add a hidden layer and define a procedure for applying the transformations?\n",
    "- Can I compute the gradient vector from the loss function?\n",
    "\n",
    "Let's construct the weights from scratch again to gain an intuition for how this can be made into a procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert training data into an np.ndarray to examine its shape\n",
    "pixel_grid = np.array(x_train[0])\n",
    "\n",
    "input_layer = pixel_grid.flatten()\n",
    "output_layer = np.zeros(len(set(y_train))) # 10 possible categories\n",
    "\n",
    "hidden_layer1 = np.zeros(50)\n",
    "\n",
    "weights0 = construct_random_weights_matrix(input_layer.size, hidden_layer1.size)\n",
    "weights1 = construct_random_weights_matrix(hidden_layer1.size, output_layer.size)\n",
    "\n",
    "print(f\"{pixel_grid.shape=}\")\n",
    "print(f\"{input_layer.shape=}\")\n",
    "print(f\"{hidden_layer1.shape=}\")\n",
    "print(f\"{output_layer.shape=}\")\n",
    "print(f\"{output_layer=}\")\n",
    "\n",
    "print(f\"{weights0.shape=}\")\n",
    "print(f\"{weights1.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer1 = np.dot(weights0, input_layer)\n",
    "output1 = np.dot(weights1, hidden_layer1)\n",
    "output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(label1, normalize(output1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try adding *N* hidden layers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_HIDDEN_LAYERS = 7\n",
    "\n",
    "pixel_grid = np.array(x_train[0])\n",
    "\n",
    "input_layer = pixel_grid.flatten()\n",
    "output_layer = np.zeros(len(set(y_train)))  # 10 possible categories\n",
    "\n",
    "hidden_layers: list[np.ndarray] = []\n",
    "weight_matrices = []\n",
    "\n",
    "# add hidden_layers of random length\n",
    "for _ in range(NUM_HIDDEN_LAYERS):\n",
    "    hidden_layers.append(np.zeros(random.randrange(10, 70)))\n",
    "\n",
    "# note to self: if I model a layer, I think that each layer should own\n",
    "# the weights that feed into it, not the weights that follow it, simply\n",
    "# because the output layer is more akin to a hidden layer than the input layer is.\n",
    "weight_matrices.append(\n",
    "    construct_random_weights_matrix(input_layer.size, hidden_layers[0].size)\n",
    ")\n",
    "for i in range(1, len(hidden_layers)):\n",
    "    weight_matrices.append(\n",
    "        construct_random_weights_matrix(\n",
    "            hidden_layers[i - 1].size, hidden_layers[i].size\n",
    "        )\n",
    "    )\n",
    "weight_matrices.append(\n",
    "    construct_random_weights_matrix(hidden_layers[-1].size, output_layer.size)\n",
    ")\n",
    "\n",
    "assert len(weight_matrices) == NUM_HIDDEN_LAYERS + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(\n",
    "    input_layer: np.ndarray, weights_matrices: list[np.ndarray]\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Given an input_layer and list of weight matrices,\n",
    "    perform matrix multiplication until the weights are exhausted.\n",
    "    \"\"\"\n",
    "    for weights_matrix in weights_matrices:\n",
    "        input_layer = np.dot(weights_matrix, input_layer)\n",
    "    return input_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = forward_propagate(input_layer, weight_matrices)\n",
    "output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial assisted\n",
    "\n",
    "First, get the training data into the correct shape.  I'll stick with row-major format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = np.array(x_train).reshape(len(x_train), -1)\n",
    "labels = np.array(y_train)\n",
    "input_layer_size = examples.shape[1]\n",
    "hidden_layer_size = 10\n",
    "output_layer_size = len(set(labels)) # number of categories\n",
    "\n",
    "print(f\"{examples.shape=}\")\n",
    "print(f\"{labels.shape=}\")\n",
    "print(f\"{input_layer_size=}\")\n",
    "print(f\"{hidden_layer_size=}\")\n",
    "print(f\"{output_layer_size=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV_SIZE = 1000\n",
    "X_dev = examples[:DEV_SIZE]\n",
    "Y_dev = labels[:DEV_SIZE]\n",
    "\n",
    "X_train = examples[DEV_SIZE:]\n",
    "Y_train = labels[DEV_SIZE:]\n",
    "\n",
    "X_dev.shape, Y_dev.shape, X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(Z: np.ndarray) -> np.ndarray:\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "\n",
    "def deriv_ReLU(Z: np.ndarray) -> np.ndarray:\n",
    "    return Z > 0\n",
    "\n",
    "\n",
    "def softmax(Z: np.ndarray) -> np.ndarray:\n",
    "    return np.exp(Z) / np.sum(np.exp(Z))\n",
    "\n",
    "\n",
    "def one_hot(Y: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Constructs a matrix whose rows represent\n",
    "    the labels (Y), and for each row, a 1 exists\n",
    "    in the column corresponding to the value of that\n",
    "    label.  All other entries are 0.\n",
    "    \"\"\"\n",
    "    one_hot_Y = np.zeros((Y.size, output_layer_size))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    return one_hot_Y\n",
    "\n",
    "\n",
    "def forward_prop(\n",
    "    X: np.ndarray,\n",
    "    W1: np.ndarray,\n",
    "    b1: np.ndarray,\n",
    "    W2: np.ndarray,\n",
    "    b2: np.ndarray,\n",
    "):\n",
    "    Z1 = W1.dot(X.T).T + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = W2.dot(A1.T).T + b2\n",
    "    A2 = softmax(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "\n",
    "def back_prop(\n",
    "    Y: np.ndarray,\n",
    "    Z1: np.ndarray,\n",
    "    A1: np.ndarray,\n",
    "    Z2: np.ndarray,\n",
    "    A2: np.ndarray,\n",
    "    W2: np.ndarray,\n",
    "):\n",
    "    m = Y.size\n",
    "    ohY = one_hot(Y)\n",
    "    dZ2 = A2 - ohY\n",
    "    dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "    db2 = 1 / m * np.sum(dZ2, 1)\n",
    "    dZ1 = W2.T.dot(dZ2) * deriv_ReLU(Z1)\n",
    "    dW1 = 1 / m * dZ1.dot(Y)\n",
    "    db1 = 1 / m * np.sum(dZ1, 1)\n",
    "\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 = W1 - alpha * dW1[:, None]\n",
    "    b1 = b1 - alpha * db1\n",
    "    W2 = W2 - alpha * dW2[:, None]\n",
    "    b2 = b2 - alpha * db2\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "\n",
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, 0)\n",
    "\n",
    "\n",
    "def compute_accuracy(predictions, Y):\n",
    "    return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "\n",
    "def gradient_descent(X, Y, iterations, alpha):\n",
    "    W1, b1, W2, b2 = init_params()\n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2 = forward_prop(X, W1, b1, W2, b2)\n",
    "        dW1, db1, dW2, db2 = back_prop(Y, Z1, A1, Z2, A2, W2)\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        if i % 50 == 0:\n",
    "            a = compute_accuracy(get_predictions(A2), Y)\n",
    "            print(f\"iteration: {i}\")\n",
    "            print(f\"accuracy: {a}\")\n",
    "\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "\n",
    "# initialize the parameters\n",
    "def init_params():\n",
    "    W1 = np.random.rand(hidden_layer_size, input_layer_size) - 0.5\n",
    "    b1 = np.random.randn(hidden_layer_size) - 0.5\n",
    "    W2 = np.random.rand(output_layer_size, hidden_layer_size) - 0.5\n",
    "    b2 = np.random.randn(output_layer_size) - 0.5\n",
    "    return W1, b1, W2, b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1, b1, W2, b2 = gradient_descent(examples, labels, 100, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "b = np.array([5,3,3,4])\n",
    "a.dot(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
