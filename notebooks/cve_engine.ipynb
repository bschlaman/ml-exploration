{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVE Analysis Engine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cvss\n",
    "import cvss.exceptions\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"../data/cve/cves.json\")\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calc_cvss(v: str) -> float:\n",
    "    try:\n",
    "        return cvss.CVSS3(v).scores()[0]\n",
    "    except cvss.exceptions.CVSS3MalformedError:\n",
    "        return -1.0\n",
    "\n",
    "\n",
    "df[\"scores\"] = df[\"XYZ_CVSS_VECTOR\"].dropna().apply(_calc_cvss)\n",
    "df[\"bad\"] = df[\"XYZ_CVSS_SCORE\"].notna() & (df[\"XYZ_CVSS_SCORE\"] != df[\"scores\"])\n",
    "df[[\"XYZ_CVSS_SCORE\", \"scores\", \"bad\"]].to_csv(\"../output.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 1: Logistic Regression\n",
    "\n",
    "Logistic Regression is often referred to as the _discriminative_\n",
    "counterpart of Naive Bayes.\n",
    "\n",
    "Model $P(y | \\mathbf{x}_i)$ and assume it takes exactly the form\n",
    "\n",
    "$$\n",
    "    P(y | \\mathbf{x}_i) = \\frac{1}{1 + e^{-y(\\mathbf{w}^T\\mathbf{x}_i + b)}}\n",
    "$$\n",
    "\n",
    "while making few assumptions about $P(\\mathbf{x}_i | y)$.\n",
    "Ultimately it doesn't matter, because we estimate $\\mathbf{w}$ and $b$\n",
    "directly with MLE or MAP to maximize the conditional likelihood of\n",
    "\n",
    "$$\n",
    "    \\prod_i P(y_i | \\mathbf{x}_i; \\mathbf{w}, b)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLE\n",
    "\n",
    "Choose parameters that maximize the conditional likelihood.\n",
    "The conditional data likelihood $P(\\mathbf{y} | X, \\mathbf{w})$\n",
    "is the probability of the observed values $\\mathbf{y} \\in \\mathbb{R}^n$\n",
    "in the training data conditioned on the feature values $\\mathbf{x}_i$.\n",
    "Note that $X = [\\mathbf{x}_1,\\dots,\\mathbf{x}_n] \\in \\mathbb{R}^{d \\times n}$.\n",
    "We choose the parameters that maximize this function, and we assume that\n",
    "the $y_i$ are independent given the input features $\\mathbf{x}_i$ and $\\mathbf{w}$.\n",
    "\n",
    "> In my view, for CVE vectors, this assumption is perfectly valid to make\n",
    "\n",
    "$$\n",
    "    P(\\mathbf{y} | X, \\mathbf{w}) = \\prod_{i=1}^{n} P(y_i | \\mathbf{x}_i, \\mathbf{w}) \\\\\n",
    "    \\hat{\\mathbf{w}}_{\\text{MLE}}\n",
    "    = \\underset{\\mathbf{w}}{\\arg\\max}\n",
    "    - \\sum_{i=1}^{n}\\log(1 + e^{-y_i\\mathbf{w}^T\\mathbf{x}_i}) \\\\\n",
    "    = \\underset{\\mathbf{w}}{\\arg\\min} \\sum_{i=1}^{n}\\log(1 + e^{-y_i\\mathbf{w}^T\\mathbf{x}_i})\n",
    "$$\n",
    "\n",
    "Use gradient descent on the _negative log likelihood_.\n",
    "\n",
    "$$\n",
    "    \\ell(\\mathbf{w}) = \\sum_{i=1}^{n}\\log(1 + e^{-y_i\\mathbf{w}^T\\mathbf{x}_i})\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preprocessing\n",
    "\n",
    "1. lowercase all text\n",
    "1. remove punctuation\n",
    "1. tokenize\n",
    "1. remove stop words\n",
    "1. lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "\n",
    "def desc_preprocess(d: str):\n",
    "    # setup\n",
    "    stopwords = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "    # lowercase\n",
    "    d = d.lower()\n",
    "    # remove punctuation\n",
    "    d = d.translate(str.maketrans(string.punctuation, \" \"*len(string.punctuation)))\n",
    "    # tokenize\n",
    "    tokens = d.split()\n",
    "    # remove stop words\n",
    "    tokens = [t for t in tokens if t not in stopwords]\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DESCRIPTION\"].apply(desc_preprocess).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def create_bow(descs: pd.Series) -> np.ndarray:\n",
    "    return CountVectorizer().fit_transform(descs).toarray()\n",
    "\n",
    "X = create_bow(df[\"DESCRIPTION\"])\n",
    "\n",
    "len(X), len(X.T)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem statement\n",
    "\n",
    "There are two sides to my problem:\n",
    "\n",
    "1. **Given input descriptions, predict the cvss vector.**\n",
    "   This is a multi-label, multi-class classification problem.\n",
    "   Some potential strategies are defined below.\n",
    "1. **Given input descriptions, suggest a cvss score directly.**\n",
    "   This is probably a regression problem, although it can\n",
    "   be converted into a classification problem with buckets\n",
    "   score buckets of some discrete size.\n",
    "\n",
    "- Independent labels: train a separate classifier for each label, probably using softmax regression\n",
    "- Dependent labels: classifier chains - input to a classifier includes output from another\n",
    "- Dependent labels: label powerset - transform problem into a multi-class problem\n",
    "  with one multi-class classifier is trained on all unique label combinations\n",
    "  found in the training data.  Deals efficiently with label correlations.\n",
    "\n",
    "I need to make a decision regarding the independence assumption of my labels.\n",
    "I find it intellectually interesting to explore the correlation statistics\n",
    "between the category + label combinations.  Two methods for establishing\n",
    "correlation between categories is\n",
    "- Chi-square test of independence\n",
    "- Cramer's V\n",
    "\n",
    "#### Next steps\n",
    "\n",
    "- Look at documentation to make sure I've got my problem statements right.\n",
    "  Does vector suggestion deliver value?\n",
    "- Perform a *Cramer's V* analysis on training examples\n",
    "- Based on the output of this, decide on ml strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "metrics = {\n",
    "    \"AV\": \"Attack Vector\",\n",
    "    \"AC\": \"Attack Complexity\",\n",
    "    \"PR\": \"Privileges Required\",\n",
    "    \"UI\": \"User Interaction\",\n",
    "    \"S\": \"Scope\",\n",
    "    \"C\": \"Confidentiality\",\n",
    "    \"I\": \"Integrity\",\n",
    "    \"A\": \"Availability\",\n",
    "}\n",
    "\n",
    "\n",
    "def _vec_parse(vec: str, metric: str):\n",
    "    return cvss.CVSS3(vec).get_value_description(metric)\n",
    "\n",
    "def clean_cvss_vector(vec: Union[str, float]) -> Union[str, float]:\n",
    "    if pd.isna(vec): return np.nan\n",
    "    try:\n",
    "        return cvss.CVSS3(vec).clean_vector()\n",
    "    except cvss.exceptions.CVSS3MalformedError:\n",
    "        pass\n",
    "\n",
    "    # fix common problems\n",
    "    assert type(vec) is str\n",
    "    vec = vec.upper()\n",
    "    vec = vec.rstrip(\".\")\n",
    "    vec = vec.replace(\" \", \"\")\n",
    "    vec = vec.rstrip(\"/\")\n",
    "    try:\n",
    "        vec = \"CVSS:3.1/\" + vec[vec.index(\"AV:\"):]\n",
    "    except ValueError:\n",
    "        pass\n",
    "    # vec = vec.removeprefix(\"VECTOR:\")\n",
    "    # if vec.startswith(\"AV\"): vec = \"CVSS:3.1/\" + vec\n",
    "    # if vec.startswith(\"/AV\"): vec = \"CVSS:3.1\" + vec\n",
    "\n",
    "    # try again\n",
    "    try:\n",
    "        return cvss.CVSS3(vec).clean_vector()\n",
    "    except cvss.exceptions.CVSS3MalformedError:\n",
    "        return np.nan\n",
    "    \n",
    "\n",
    "def extract_cvss_vector_components(df: pd.DataFrame, vector: pd.Series):\n",
    "    for metric in metrics.keys():\n",
    "        df[metric] = vector.dropna().apply(lambda v: _vec_parse(v, metric))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"vector\"] = df.XYZ_CVSS_VECTOR.apply(clean_cvss_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_cvss_vector_components(df, df[\"vector\"])\n",
    "print(df[\"vector\"].count())\n",
    "\n",
    "df.to_csv(\"../asdf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[df[metric].count() for metric in metrics.keys()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson's $\\Chi^2$ test\n",
    "\n",
    "- [Pearson's chi-squared test - Wikipedia](https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test)\n",
    "\n",
    "Based on the below analysis, a couple of the highest correlations:\n",
    "\n",
    "- AV:L & PR:L highly correlated\n",
    "- AV:N & PR:L highly negatively correlated\n",
    "- PR:L & UI:R highly negatively correlated\n",
    "- PR:N & UI:R highly correlated\n",
    "- PR:H & S:C highly correlated\n",
    "- I:L & S:C very highly correlated\n",
    "- A:N & S:C very highly correlated\n",
    "- C:* & I* extemely correlated both positively and negatively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import itertools\n",
    "\n",
    "crosstabs = {}\n",
    "\n",
    "def perform_independence_test(df: pd.DataFrame):\n",
    "    for c0, c1 in itertools.combinations(metrics.keys(), 2):\n",
    "        xtab = pd.crosstab(df[c0], df[c1])\n",
    "        crosstabs[\":\".join((c0,c1))] = xtab\n",
    "        print(f\"\\n=== {c0} & {c1}\")\n",
    "        print(sm.stats.Table(xtab).resid_pearson)\n",
    "\n",
    "perform_independence_test(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for statistical significance of cross-category dependence\n",
    "\n",
    "$H_{0_{\\alpha, \\beta}}$: metric $\\alpha$ and metric $\\beta$ are independent\n",
    "\n",
    "Use standard significance level $\\alpha = 0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "xtab = crosstabs[\"C:I\"]\n",
    "alpha = 0.5\n",
    "chi2stat, pvalue, dof, expected_frequency = scipy.stats.chi2_contingency(xtab)\n",
    "chi2stat, pvalue, dof, expected_frequency, pvalue <= alpha"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding CVSS Vectors\n",
    "\n",
    "The following table lists out the metrics comprised by the CVSS vector.\n",
    "More info can be found in the [CVSS v3.1 Specification Document](https://www.first.org/cvss/specification-document).\n",
    "Each metric contributes a predefined amount to the overall CVE CVSS score,\n",
    "and the score is completely determined by the values of these metrics.\n",
    "Values in the table below are ordered from most to least severe.\n",
    "\n",
    "| **Base metric** | **Base metric type** | **Description** | **Possible values** |\n",
    "|---|---|---|---|\n",
    "| Attack Vector (AV) | Exploitability | This metric reflects the context by which vulnerability exploitation is possible. | Network, Adjacent, Local, Physical |\n",
    "| Attack Complexity (AC) | Exploitability | This metric describes the conditions beyond the attacker’s control that must exist in order to exploit the vulnerability. | Low, High |\n",
    "| Privileges Required (PR) | Exploitability | This metric describes the level of privileges an attacker must possess before successfully exploiting the vulnerability. | None, Low, High |\n",
    "| User Interaction (UI) | Exploitability | This metric captures the requirement for a human user, other than the attacker, to participate in the successful compromise of the vulnerable component. | None, Required |\n",
    "| Scope (S) | Scope¹ | The Scope metric captures whether a vulnerability in one vulnerable component impacts resources in components beyond its security scope. | Changed, Unchanged |\n",
    "| Confidentiality (C) | Impact | This metric measures the impact to the confidentiality of the information resources managed by a software component due to a successfully exploited vulnerability. | High, Low, None |\n",
    "| Integrity (I) | Impact | This metric measures the impact to integrity of a successfully exploited vulnerability. | High, Low, None |\n",
    "| Availability (A) | Impact | This metric measures the impact to the availability of the impacted component resulting from a successfully exploited vulnerability. | High, Low, None |\n",
    "\n",
    "<br>\n",
    "\n",
    "> ¹Scope was introduced in CVSS3.1.\n",
    "\n",
    "For our model, the precise meaning of these metrics and their subcategories is unimportant.\n",
    "The relevant question is: _how independent are these metrics and subcategories?_\n",
    "\n",
    "Assumption of label independence certainly makes our job easier,\n",
    "as it leaves the door open for more basic machine learning algorithms\n",
    "like **multi-category logistic regression**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "# Generate two sets of data\n",
    "data1 = np.random.normal(0, 1, 1000)\n",
    "data2 = np.random.normal(0.1, 1, 1000)\n",
    "\n",
    "# Perform a t-test\n",
    "t_stat, p_value = scipy.stats.ttest_ind(data1, data2)\n",
    "\n",
    "print(f\"t-statistic: {t_stat}\")\n",
    "print(f\"p-value: {p_value}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to understand if the results in the crosstable are statistically significant\n",
    "Then, select an approach for training (multi-class log reg?)\n",
    "\n",
    "Then, try a basic run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
