{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using sklearn to preprocess CVE data\n",
    "\n",
    "[Working With Text Data — scikit-learn 1.3.2 documentation](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import sklearn.pipeline\n",
    "import sklearn.feature_extraction.text\n",
    "import sklearn.linear_model\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cve_engine.cvss_data import CVSS_BASE_METRICS\n",
    "from cve_engine.data_processing import (\n",
    "    clean_cvss_vector,\n",
    "    create_bow,\n",
    "    desc_preprocess,\n",
    "    vec_parse_metric,\n",
    ")\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"[%(levelname)-8s] (%(name)s) %(message)s\",\n",
    "    level=logging.DEBUG,\n",
    ")\n",
    "log = logging.getLogger(__name__)\n",
    "logging.getLogger(\"cve_engine.data_processing\").setLevel(logging.INFO)\n",
    "logging.getLogger(\"matplotlib\").setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "def load_cves():\n",
    "    \"\"\"Loads all cve data, indexed by cve_id\"\"\"\n",
    "    cves = {}\n",
    "    for subdir in (\"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\"):\n",
    "        path = os.path.join(\"../data/cve\", subdir)\n",
    "        for file in os.listdir(path):\n",
    "            with open(os.path.join(path, file)) as f:\n",
    "                cves[file.removesuffix(\".json\")] = json.load(f)\n",
    "    return cves\n",
    "\n",
    "\n",
    "def construct_training_set(cves: dict):\n",
    "    \"\"\"\n",
    "    Scan through all CVEs for cve.source_data elements.\n",
    "    For each element, couple the cve.source_data.elem.description\n",
    "    with each cve.source_data.elem.score.\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    for cve_data in cves.values():\n",
    "        for sd in cve_data[\"source_data\"]:\n",
    "            if \"scores\" not in sd:\n",
    "                continue\n",
    "            examples.extend(\n",
    "                [{\"description\": sd[\"description\"]} | score for score in sd[\"scores\"]]\n",
    "            )\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_path = \"../cves.pkl\"\n",
    "\n",
    "if os.path.isfile(pkl_path):\n",
    "    with open(pkl_path, \"rb\") as f:\n",
    "        cves = pickle.load(f)\n",
    "else:\n",
    "    # can take a few seconds\n",
    "    cves = load_cves()\n",
    "    with open(pkl_path, \"wb\") as f:\n",
    "        pickle.dump(cves, f)\n",
    "\n",
    "print(f\"{sys.getsizeof(cves) / 1e6} mb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(construct_training_set(cves))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cvss_vector_components(df: pd.DataFrame, vector: pd.Series):\n",
    "    for metric in CVSS_BASE_METRICS:\n",
    "        df[metric] = vector.dropna().apply(lambda v: vec_parse_metric(v, metric))\n",
    "    return df\n",
    "\n",
    "log.info(\"cleaning cvss vectors\")\n",
    "df[\"vector_clean\"] = df[\"vector\"].apply(clean_cvss_vector)\n",
    "log.info(\"processing descriptions\")\n",
    "df[\"processed_desc\"] = df[\"description\"].apply(desc_preprocess)\n",
    "log.info(\"extracting cvss vector components\")\n",
    "df = extract_cvss_vector_components(df, df[\"vector_clean\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only this compact version is used going forward\n",
    "df_clean = df.dropna(subset=\"vector_clean\").copy()\n",
    "# remove descriptions with REJECT in them\n",
    "df_clean.drop(df_clean.index[df_clean[\"description\"].str.contains(\"REJECT\")], inplace=True)\n",
    "df_clean.drop(df_clean.index[df_clean[\"description\"].apply(str.lower).str.contains(\"no description is available for this cve\")], inplace=True)\n",
    "df_clean.drop_duplicates(subset=\"cve_id\", inplace=True)\n",
    "# note it may also be prudent to dedupe on description,\n",
    "# but I'll leave this for now considering the CVE_IDs are different\n",
    "df_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "    df_clean[\"description\"], df_clean[metric], test_size=0.3, random_state=9\n",
    ")\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = sklearn.pipeline.Pipeline(\n",
    "    [\n",
    "        (\"vect\", sklearn.feature_extraction.text.CountVectorizer()),\n",
    "        (\"tfidf\", sklearn.feature_extraction.text.TfidfTransformer()),\n",
    "        (\n",
    "            \"clf\",\n",
    "            sklearn.linear_model.SGDClassifier(\n",
    "                # loss=\"hinge\",\n",
    "                # penalty=\"l2\",\n",
    "                alpha=1e-5,\n",
    "                # random_state=42,\n",
    "                max_iter=50,\n",
    "                tol=None,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(y_test, text_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "\n",
    "sklearn.metrics.ConfusionMatrixDisplay(\n",
    "    confusion_matrix=sklearn.metrics.confusion_matrix(y_test, text_clf.predict(X_test)),\n",
    "    display_labels=text_clf.classes_,\n",
    ").plot(ax=ax, cmap=plt.cm.PuRd)\n",
    "\n",
    "ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"vect__ngram_range\": [(1, 1), (1, 2), (1, 3)],\n",
    "    \"clf__alpha\": (1e-4, 1e-5, 1e-6),\n",
    "    # \"clf__tol\": (1e-3, None),\n",
    "    # \"clf__loss\": (\"hinge\", \"squared_hinge\"),\n",
    "    # \"clf__max_iter\": (5, 10, 50),\n",
    "}\n",
    "\n",
    "gs = sklearn.model_selection.GridSearchCV(\n",
    "    text_clf,\n",
    "    param_grid,\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(y_test, gs.predict(X_test)))\n",
    "print(sklearn.metrics.accuracy_score(y_test, gs.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "\n",
    "sklearn.metrics.ConfusionMatrixDisplay(\n",
    "    confusion_matrix=sklearn.metrics.confusion_matrix(y_test, gs.predict(X_test)),\n",
    "    display_labels=text_clf.classes_,\n",
    ").plot(ax=ax, cmap=plt.cm.PuRd)\n",
    "\n",
    "ax.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "- look up how to deal with data imbalances\n",
    "- understand the classification report and decide upon a CV scoring that makes sense\n",
    "- record an initial set of best params for each metric (e.g. \"C\" preferred (1,3) grams)\n",
    "- understand this: [3.2. Tuning the hyper-parameters of an estimator — scikit-learn 1.3.2 documentation](https://scikit-learn.org/stable/modules/grid_search.html#specifying-multiple-metrics-for-evaluation)\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "519/(519+99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import harmonic_mean\n",
    "\n",
    "x = 0.1\n",
    "data = [x, 1-x]\n",
    "\n",
    "harmonic_mean(data), np.exp(np.log(data).mean()), np.prod(data)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Further EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "\n",
    "df_melted = df_clean[list(CVSS_BASE_METRICS.keys())].melt(\n",
    "    var_name=\"metric_key\", value_name=\"category\"\n",
    ")\n",
    "\n",
    "df_grouped = df_melted.groupby([\"metric_key\", \"category\"]).size().unstack()\n",
    "df_grouped.index = df_grouped.index.map(\n",
    "    {k: v.name for k, v in CVSS_BASE_METRICS.items()}\n",
    ")\n",
    "\n",
    "ax = df_grouped.plot(kind=\"bar\", stacked=True)\n",
    "plt.ylabel(\"Category counts\")\n",
    "plt.xlabel(\"CVSS Metric\")\n",
    "plt.title(\"CVSS Metric Category Values\")\n",
    "\n",
    "for i, (index, row) in enumerate(df_grouped.iterrows()):\n",
    "    cumulative_size = 0\n",
    "\n",
    "    for col in df_grouped.columns:\n",
    "        value = row[str(col)]\n",
    "\n",
    "        if np.isnan(value):\n",
    "            continue\n",
    "\n",
    "        x_position = i\n",
    "        y_position = cumulative_size + (value / 2)\n",
    "\n",
    "        ax.text(x_position, y_position, str(col), ha=\"center\", va=\"center\")\n",
    "\n",
    "        cumulative_size += value\n",
    "\n",
    "ax.legend().remove()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../stacks_big_dataset.png\", dpi=500)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
