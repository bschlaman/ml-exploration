{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVE Predictor Engine\n",
    "The goal of this notebook is to start fresh and implement new techniques like *conditional entropy sorting*\n",
    "to reduce feature dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: GPU Training / Benchmarking\n",
    "\n",
    "Before implementing any new techniques, I want to benchmark the training process to compare\n",
    "CPU training vs GPU training with an `Intel Arc A370M` on my HP Spectre x16.\n",
    "\n",
    "Results:\n",
    "- CPU with dim 23228 for `AV` 70sec / 100 epochs\n",
    "\n",
    "----\n",
    "\n",
    "#### Training attempt with max vector contributions\n",
    "\n",
    "Note to self: each index in `cves` has an array called `source_data`;\n",
    "this is my true raw data.  If a `source_data` entry has all of the following, I will include it.\n",
    "1. `cve_id`\n",
    "1. `description`\n",
    "1. `scores.[].vector`\n",
    "\n",
    "The parent description should be copied to each of the vectors in `scores`.\n",
    "\n",
    "**Important:** some of this code is copy-pasta from the other notebook and may diverge slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the intel drivers\n",
    "# required for torch import to work\n",
    "# \"jupyter.runStartupCommands\": []\n",
    "# below doesn't work; the only thing that works is to\n",
    "# source the env files before starting vscode such that\n",
    "# vscode inherits the variables...\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import sys\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def load_cves():\n",
    "    \"\"\"Loads all cve data, indexed by cve_id\"\"\"\n",
    "    cves = {}\n",
    "    for subdir in (\"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\"):\n",
    "        path = os.path.join(\"../data/cve\", subdir)\n",
    "        for file in os.listdir(path):\n",
    "            with open(os.path.join(path, file)) as f:\n",
    "                cves[file.removesuffix(\".json\")] = json.load(f)\n",
    "    return cves\n",
    "\n",
    "\n",
    "def construct_training_set(cves: dict):\n",
    "    \"\"\"\n",
    "    Scan through all CVEs for cve.source_data elements.\n",
    "    For each element, couple the cve.source_data.elem.description\n",
    "    with each cve.source_data.elem.score.\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    for cve_data in cves.values():\n",
    "        for sd in cve_data[\"source_data\"]:\n",
    "            if \"scores\" not in sd:\n",
    "                continue\n",
    "            examples.extend(\n",
    "                [{\"description\": sd[\"description\"]} | score for score in sd[\"scores\"]]\n",
    "            )\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_path = \"../cves.pkl\"\n",
    "\n",
    "if os.path.isfile(pkl_path):\n",
    "    with open(pkl_path, \"rb\") as f:\n",
    "        cves = pickle.load(f)\n",
    "else:\n",
    "    # can take a few seconds\n",
    "    cves = load_cves()\n",
    "    with open(pkl_path, \"wb\") as f:\n",
    "        pickle.dump(cves, f)\n",
    "\n",
    "print(f\"{sys.getsizeof(cves) / 1e6} mb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(construct_training_set(cves))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from cve_engine.cvss_data import CVSS_BASE_METRICS\n",
    "from cve_engine.data_processing import (\n",
    "    clean_cvss_vector,\n",
    "    desc_preprocess,\n",
    "    vec_parse_metric,\n",
    "    create_bow,\n",
    ")\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"[%(levelname)-8s] (%(name)s) %(message)s\",\n",
    "    level=logging.DEBUG,\n",
    ")\n",
    "log = logging.getLogger(__name__)\n",
    "logging.getLogger(\"cve_engine.data_processing\").setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "def extract_cvss_vector_components(df: pd.DataFrame, vector: pd.Series):\n",
    "    for metric in CVSS_BASE_METRICS:\n",
    "        df[metric] = vector.dropna().apply(lambda v: vec_parse_metric(v, metric))\n",
    "    return df\n",
    "\n",
    "log.info(\"cleaning cvss vectors\")\n",
    "df[\"vector_clean\"] = df[\"vector\"].apply(clean_cvss_vector)\n",
    "log.info(\"processing descriptions\")\n",
    "df[\"processed_desc\"] = df[\"description\"].apply(desc_preprocess)\n",
    "log.info(\"extracting cvss vector components\")\n",
    "df = extract_cvss_vector_components(df, df[\"vector_clean\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only this compact version is used going forward\n",
    "df_clean = df.dropna(subset=[\"vector_clean\"]).copy()\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "for metric in CVSS_BASE_METRICS.keys():\n",
    "    encoder = LabelEncoder()\n",
    "    df_clean[metric + \"_Y\"] = encoder.fit_transform(df_clean[metric])\n",
    "\n",
    "Y_np = df_clean[[metric + \"_Y\" for metric in CVSS_BASE_METRICS.keys()]].values\n",
    "Y = torch.from_numpy(Y_np)\n",
    "\n",
    "Y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data and create Y matrices\n",
    "train_split = 0.8\n",
    "i = int(train_split * len(Y))\n",
    "X_train_raw, X_test_raw = df_clean[\"processed_desc\"][:i], df_clean[\"processed_desc\"][i:]\n",
    "Y_train, Y_test = Y[:i], Y[i:]\n",
    "\n",
    "# compute X_train_np just so we can examine the shape;\n",
    "# the actual X_train will be constructed just before training\n",
    "bow_vec, X_train_np = create_bow(X_train_raw.to_list())\n",
    "X_train_np.shape, Y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cve_engine.engine import CVEEngineModel\n",
    "\n",
    "cvem = CVEEngineModel()\n",
    "\n",
    "load = False\n",
    "if load:\n",
    "    cvem.load_latest_models()\n",
    "    cvem.display_parameters()\n",
    "else:\n",
    "    cvem.new_model(bow_vec)\n",
    "    # this crashes every time (at least on my spectre; not sure about other machines)\n",
    "    # cvem.optimize_intel_ipex()\n",
    "    cvem.display_parameters()\n",
    "    # ~2 min for 100 epochs\n",
    "    # with cuda: much faster!  30 min for full training run\n",
    "    cvem.train_all(X_train_raw.to_numpy(), Y_train)\n",
    "    # cvem.train_all_v2(X_train_raw.to_numpy(), Y_train, X_test_raw.to_numpy(), Y_test)\n",
    "    cvem.save_models_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, cs = cvem.predict(X_test_raw.to_numpy())\n",
    "pred, cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pct correct\n",
    "np.mean(Y_test.numpy() == pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average confidence scores\n",
    "np.mean(cs, axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
