{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Practice on the MNIST data set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "from array import array\n",
    "\n",
    "\n",
    "class MnistDataloader(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        training_images_filepath,\n",
    "        training_labels_filepath,\n",
    "        test_images_filepath,\n",
    "        test_labels_filepath,\n",
    "    ):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "\n",
    "    def read_images_labels(self, images_filepath, labels_filepath):\n",
    "        labels = []\n",
    "        with open(labels_filepath, \"rb\") as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError(\n",
    "                    \"Magic number mismatch, expected 2049, got {}\".format(magic)\n",
    "                )\n",
    "            labels = array(\"B\", file.read())\n",
    "\n",
    "        with open(images_filepath, \"rb\") as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError(\n",
    "                    \"Magic number mismatch, expected 2051, got {}\".format(magic)\n",
    "                )\n",
    "            image_data = array(\"B\", file.read())\n",
    "        images = []\n",
    "        for i in range(size):\n",
    "            images.append([0] * rows * cols)\n",
    "        for i in range(size):\n",
    "            img = np.array(image_data[i * rows * cols : (i + 1) * rows * cols])\n",
    "            img = img.reshape(28, 28)\n",
    "            images[i][:] = img\n",
    "\n",
    "        return images, labels\n",
    "\n",
    "    def load_data(self):\n",
    "        x_train, y_train = self.read_images_labels(\n",
    "            self.training_images_filepath, self.training_labels_filepath\n",
    "        )\n",
    "        x_test, y_test = self.read_images_labels(\n",
    "            self.test_images_filepath, self.test_labels_filepath\n",
    "        )\n",
    "        return (x_train, y_train), (x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "data_base_path = '../../../../data/mnist'\n",
    "training_images_filepath = os.path.join(data_base_path, 'train-images-idx3-ubyte/train-images-idx3-ubyte')\n",
    "training_labels_filepath = os.path.join(data_base_path, 'train-labels-idx1-ubyte/train-labels-idx1-ubyte')\n",
    "test_images_filepath = os.path.join(data_base_path, 't10k-images-idx3-ubyte/t10k-images-idx3-ubyte')\n",
    "test_labels_filepath = os.path.join(data_base_path, 't10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')\n",
    "\n",
    "def show_images(images, title_texts):\n",
    "    cols = 5\n",
    "    rows = int(len(images)/cols) + 1\n",
    "    plt.figure(figsize=(30,20))\n",
    "    index = 1    \n",
    "    for x in zip(images, title_texts):        \n",
    "        image = x[0]        \n",
    "        title_text = x[1]\n",
    "        plt.subplot(rows, cols, index)        \n",
    "        plt.imshow(image, cmap=plt.cm.gray)\n",
    "        if (title_text != ''):\n",
    "            plt.title(title_text, fontsize = 15);        \n",
    "        index += 1\n",
    "\n",
    "mnist_dataloader = MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)\n",
    "(x_train, y_train), (x_test, y_test) = mnist_dataloader.load_data()\n",
    "\n",
    "images_2_show = []\n",
    "titles_2_show = []\n",
    "for i in range(0, 10):\n",
    "    r = random.randint(1, 60000)\n",
    "    images_2_show.append(x_train[r])\n",
    "    titles_2_show.append('training image [' + str(r) + '] = ' + str(y_train[r]))    \n",
    "\n",
    "for i in range(0, 5):\n",
    "    r = random.randint(1, 10000)\n",
    "    images_2_show.append(x_test[r])        \n",
    "    titles_2_show.append('test image [' + str(r) + '] = ' + str(y_test[r]))    \n",
    "\n",
    "show_images(images_2_show, titles_2_show)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifying the shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    [\n",
    "        (\"x_train\", type(x_train), \"Raw image data\"),\n",
    "        (\n",
    "            \"x_train[0]\",\n",
    "            type(x_train[0]),\n",
    "            \"2D array representing pixel values for a single image\",\n",
    "        ),\n",
    "        (\"y_train\", type(y_train), \"Labels\"),\n",
    "    ],\n",
    "    columns=[\"variable\", \"type\", \"description\"],\n",
    ")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train), len(x_train[0]), len(x_train[0][0]), type(x_train[0][0]), type(x_train[0][0][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct input and output layers\n",
    "\n",
    "The next step is to construct a random neural network.  I'll start by constructing the input layer and output layer.\n",
    "\n",
    "First, define some utilities:\n",
    "\n",
    "1. need a way to flatten a 28x28 image into a single list\n",
    "2. need a method to normalize a list of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from typing import Iterable, Sequence, TypeVar\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "def flatten_2d_data(data: Iterable[Iterable[T]]) -> list[T]:\n",
    "    \"\"\"Flatten a 2d matrix into a 1d matrix by\n",
    "    chaining together each row into a list.\n",
    "    \"\"\"\n",
    "    # return itertools.chain.from_iterable(data)\n",
    "    return list(itertools.chain.from_iterable(data))\n",
    "\n",
    "def normalize(a: np.ndarray) -> np.ndarray:\n",
    "    return a / np.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_len = len(x_train[0]) * len(x_train[0][0])\n",
    "output_layer = np.zeros(10)\n",
    "print(f\"{input_layer_len=}\")\n",
    "print(f\"{output_layer=}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct random weights matrix\n",
    "\n",
    "`np.random.randn` returns values from the standard normal distribution, a common initialization\n",
    "method for neural networks.\n",
    "\n",
    "The matrix must be of size `len(output)` x `len(input)`, which makes sense as a linear transformation\n",
    "from dimensionality 784 to dimensionality 10.\n",
    "\n",
    "Here I scale the inital weights by 0.01, a relatively arbitrary value.  The values should be small because in a network with many layers, large initial weights can lead to large outputs from neurons, which when passed through an activation function (like a sigmoid or a tanh), might end up in the saturation region of the function. This can lead to vanishing gradients during backpropagation, making the network harder to train.\n",
    "\n",
    "Note that techniques like Xavier initialization and He initialization improve upon this random method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the weights with small random values\n",
    "weights = np.random.randn(output_layer.size, input_layer_len) * 0.01\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting one image\n",
    "\n",
    "Now find the output of applying the weights to the first image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image1 = normalize(flatten_2d_data(x_train[0]))\n",
    "image1 = flatten_2d_data(x_train[0])\n",
    "label1 = y_train[0]\n",
    "print(f\"{len(image1)=} {label1=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.dot(weights, image1)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = normalize(output)\n",
    "output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function\n",
    "\n",
    "Now define the *loss function*; I'll use the common **squared error loss**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(label: int, output: np.ndarray) -> float:\n",
    "    if sum(output) != 1: raise Exception(\"output must be normalized\")\n",
    "    return sum(\n",
    "        val**2 if i != label else (val - 1) ** 2 for i, val in enumerate(output)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(label1, normalize(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(output ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
